# -*- coding: utf-8 -*-
"""WebScraping_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1goTpV5mCJBWkFUvDNwmMhL8O7gnwQJmY
"""

from google.colab import drive # let google colab access your drive and prepare for storage 
drive.mount('/content/drive')
import os # check if you have an access to the drive
os.chdir("/content/drive/MyDrive/")
!ls

# Web scraping using Selenium package to collect the data for aroma chemicals
# we will focus on the following (Molecule_Name , Odor_Description , Use_level , Fragrance_Family, Molecular_Weight, Boiling_Point, Vapor_Pressure, Formula, CAS_Num )
# The data was taken from www.perfumersapprentice.com

!pip install selenium # This is only to install Selenium package with chromium-chromedriver
!apt-get update 
!apt install chromium-chromedriver
from selenium import webdriver
import time
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
driver.implicitly_wait(30) # This is to allow driver to wait in maximum 30 seceond looking for tha date (each 0.5 second will check the availability)
!pip install XlsxWriter
from google.colab import drive
from selenium.webdriver.common.by import By
import xlsxwriter

element_list = []
element_list.append(['Molecule_Name', 'Odor_Description', 'Use_level' , 
                'Fragrance_Family', 'Molecular_Weight' , 'Boiling_Point' 
                , 'Vapor_Pressure' , 'Formula' , 'CAS_Num' ])

for pageO in range(5, 6, 1): # We have in total 5 pages so the range will be from 1-6

  url= 'https://shop.perfumersapprentice.com/c-236-new-aromas.aspx?pagenum=' + str(pageO)
  driver.get(url)

  for pageI in range(1, 59, 1): # we have in total 60 aroma chemicals per page so the range will be from 1 - 61
    driver.get(url)
    time.sleep(10)
    url_element = driver.find_element(By.XPATH,'/html/body/form/main/div[1]/ul[2]/li['+str(pageI)+']/a').click() # This will enter each page to collect some information
    
    time.sleep(10) # allow python to sleep 1 second then complete the execution

    Molecule_Name = driver.find_element(By.XPATH, "/html/body/form/main/div[1]/h2").text # I take the input directly from the Xpath
      
    #Note = driver.find_element(By.XPATH,"/html/body/form/main/div[1]/div[2]/p/text()").text 

    Product_Description = driver.find_element(By.XPATH,'//*[@id="ctl00_PageContent_pnlContent"]/div[2]').text # I extract the whole project description information

    Odor_Description = Product_Description.split("Odor Description: ")[-1] # Split the data to any text below "Odor Description:"
    Odor_Description_New = Odor_Description.split("\n") # split the data using space 
    Odor_Description_New_upd = Odor_Description_New[0]+Odor_Description_New[1] # combining the arguments needed for Odor Description:

    Use_level = Product_Description.split("Use Level: ")[-1] 
    Use_level_New = Use_level.split("\n") 
    Use_level_New_upd = Use_level_New[0] 

    Fragrance_Family = Product_Description.split("Fragrance Family: ")[-1] 
    Fragrance_Family_New = Fragrance_Family.split("\n") 
    Fragrance_Family_New_upd = Fragrance_Family_New[0] 

    Molecular_Weight = Product_Description.split("Molecular Weight:  ")[-1] 
    Molecular_Weight_New = Molecular_Weight.split("\n") 
    Molecular_Weight_New_upd = Molecular_Weight_New[0] 

    Boiling_Point = Product_Description.split("Boiling Point:    ")[-1] 
    Boiling_Point_New = Boiling_Point.split("\n") 
    Boiling_Point_New_upd = Boiling_Point_New[0] 

    Vapor_Pressure = Product_Description.split("Vapour pressure ")[-1] 
    Vapor_Pressure_New = Vapor_Pressure.split("\n") 
    Vapor_Pressure_New_upd = Vapor_Pressure_New[0] 

    Formula = Product_Description.split("Formula:    ")[-1] 
    Formula_New = Formula.split("\n") 
    Formula_New_upd = Formula_New[0] 

    CAS_Num = Product_Description.split("CAS # ")[-1] 
    CAS_Num_New = CAS_Num.split("\n") 
    CAS_Num_New_upd = CAS_Num_New[0] 

    element_list.append([Molecule_Name, Odor_Description_New_upd, Use_level_New_upd,
                            Fragrance_Family_New_upd, Molecular_Weight_New_upd, Boiling_Point_New_upd,
                            Vapor_Pressure_New_upd, Formula_New_upd, CAS_Num_New_upd ] )
    
  with xlsxwriter.Workbook('/content/drive/MyDrive/result_AC.xlsx') as workbook:
      worksheet = workbook.add_worksheet()

      for row_num, data in enumerate(element_list):
          worksheet.write_row(row_num, 0, data)

driver.close()

# Web scraping using Selenium package to collect the data for Essential Oils
# we will focus on the following ( Ess_Oil_Name , Odor_Description, Perfumary_Note , Family, Ext_Method , Uses , Blends_with )
# The data was taken from www.edensgarden.com

!pip install selenium # This is only to install Selenium package with chromium-chromedriver
!apt-get update 
!apt install chromium-chromedriver
from selenium import webdriver
import time
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
driver.implicitly_wait(30) # This is to allow driver to wait in maximum 30 seceond looking for tha date (each 0.5 second will check the availability)
!pip install XlsxWriter
from google.colab import drive
from selenium.webdriver.common.by import By
import xlsxwriter

element_list_Ess = []
element_list_Ess.append(['Ess_Oil_Name','Odor_Description', 'Perfumary_Note', 'Family' , 
                       'Ext_Method', 'Blends_with' ])

for pageOE in range(6, 8, 1): # We have in total 6 pages so the range will be from 1-7
  url = 'https://www.edensgarden.com/collections/single-oils?sort_by=manual&page='+str(pageOE)+'&gclid=CjwKCAiAsYyRBhACEiwAkJFKolzzuXQ0P-WLP1pDklpgLwaU8_Yv0wrIcEN1W8SOmzMhID602vfrBBoChj8QAvD_BwE'
  driver.get(url)

  for pageIE in range(1, 30, 1): # we have in total 29 essential oils per page so the range will be from 1 - 30
    driver.get(url)

    time.sleep(1)

    url_element_Ess = driver.find_element(By.XPATH,'/html/body/main/div[1]/div[1]/div[2]/div/div[2]/div[2]/div[2]/div['+str(pageIE)+']/div[2]/div[1]/p/a').click() # This will enter each page to collect some information
  
    time.sleep(1) # allow python to sleep 10 second then complete the execution

    Ess_Oil_Name = driver.find_element(By.XPATH, '//*[@id="shopify-section-product-main"]/section/div[2]/div[2]/div[2]/form/h1').text
    
    Product_Details = driver.find_element(By.XPATH, '//*[@id="shopify-section-product-main"]/section/div[2]/div[2]/div[3]/div[3]/div[2]/div').text

    Perfumary_Note = Product_Details.split("Note: ")[-1] 
    Perfumary_Note_New = Perfumary_Note.split("\n") 
    Perfumary_Note_New_upd = Perfumary_Note_New[0] 

    Family = Product_Details.split("Family: ")[-1] 
    Family_New = Family.split("\n") 
    Family_New_upd = Family_New[0] 

    Odor_Description_Ess = Product_Details.split("Aroma: ")[-1] 
    Odor_Description_Ess_New = Odor_Description_Ess.split("\n") 
    Odor_Description_Ess_New_upd = Odor_Description_Ess_New[0] 

    Blends_with = Product_Details.split("Blends Well With: ")[-1] 
    Blends_with_New = Blends_with.split("\n") 
    Blends_with_New_upd = Blends_with_New[0] 

    Ext_Method = Product_Details.split("Method: ")[-1] 
    Ext_Method_New = Ext_Method.split("\n") 
    Ext_Method_New_upd = Ext_Method_New[0] 

    #Uses = driver.find_element(By.XPATH, '/html/body/main/div[1]/div[1]/section/div[2]/div[2]/div[3]/div[1]/div[2]/div/div[1]/p').text

    element_list_Ess.append([Ess_Oil_Name, Odor_Description_Ess_New_upd, Perfumary_Note_New_upd,
                            Family_New_upd, Ext_Method_New_upd, Blends_with_New_upd ] )
    
  with xlsxwriter.Workbook('/content/drive/MyDrive/result_Ess.xlsx') as workbook:
      worksheet = workbook.add_worksheet()

      for row_num, data in enumerate(element_list_Ess):
          worksheet.write_row(row_num, 0, data)

driver.close()