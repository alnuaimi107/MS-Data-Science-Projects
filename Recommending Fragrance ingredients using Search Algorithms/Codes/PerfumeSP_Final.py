# -*- coding: utf-8 -*-
"""Copy of PerfumeSP-final (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G-fPoka3gr8OyvHv9J5QCsUTNf0-u_OH
"""

!pip install annoy
!pip install faiss
!sudo apt-get install libomp-dev
!pip install rank_bm25
!python -m spacy download en_core_web_sm

"""### Imports"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import time
import faiss
import annoy
from rank_bm25 import BM25Okapi
import tqdm
import spacy
from rank_bm25 import BM25Okapi
from tqdm import tqdm
import en_core_web_sm
nlp = en_core_web_sm.load()
import warnings
warnings.filterwarnings('ignore')

"""### Data analysis

###### Initial dataset 1
"""

import pandas as pd
df1 = pd.read_excel('Aroma_Chemical.xlsx')
df1.head(3)

df1.tail(3)

"""#### Due to NaN we need some imputation"""

df1['CAS-Number'] = df1['CAS-Number'].replace({np.nan: 'NA'})
df1['Odor_Strength'] = df1['Odor_Strength'].replace({np.nan: 'NA'})

list(df1.Perfumary_Note.unique())

df1.Perfumary_Note.value_counts()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(['Base','Middle','Top'])
df1['Perfumary_Note_1'] = le.transform(df1.Perfumary_Note)

list(df1.Odor_Strength.unique())

df1.Odor_Strength.value_counts()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(list(df1.Odor_Strength.unique()))
df1['Odor_Strength_1'] = le.transform(df1.Odor_Strength)

df1['Family'] = df1['Family'].replace({np.nan: 'None'})

df1.Family.value_counts()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(list(df1.Family.unique()))
df1['Family_1'] = le.transform(df1.Family)
df1.head()

"""### After few imputation and feature engineering here is the transformed dataset 1"""

import pandas as pd
df1 = pd.read_csv('chem_modified.csv',index_col=0)
df1.head(3)

df_v1 = df1[['Odor_Description','Perfumary_Note_1',
       'Odor_Strength_1', 'Family_1', 'sweet', 'aldehydic', 'waxy', 'citrus',
       'orange', 'fatty', 'fruity', 'moss', 'tuberose', 'coconut', 'musk',
       'wood', 'herbal', 'amber', 'animal', 'fresh', 'sandal', 'lavender',
       'floral', 'spice']]
df_v1.head(3)

"""# Search Algorithm (1) : Approximate Nearest Neighbor (vector encoding using LSH) 

1.   List item
2.   List item



#### LSH refers to a family of functions (known as LSH families) to hash data points into buckets so that data points near each other are located in the same buckets with high probability, while data points far from each other are likely to be in different buckets. This makes it easier to identify observations with various degrees of similarity.
"""

# The idea here is to spacify an external description (attribute) and find the similarities in our database

df_v2 = df_v1.set_index('Odor_Description').T.to_dict('list')
data = dict()
attr = []
vectors = []


for a,b in df_v2.items():
    attr.append(a)
    vectors.append(b)

data['attr'] = np.array(attr, dtype=object)
data['vector'] = np.array(vectors, dtype=float)

class LSHIndex():
    def __init__(self, vectors, labels):
        self.dimension = vectors.shape[1]
        self.vectors = vectors.astype('float32')
        self.labels = labels    
   
    def build(self, num_bits=8):
      self.index = faiss.IndexLSH(self.dimension, num_bits)
      self.index.add(self.vectors)
        
    def query(self, vectors, k=7):
        distances, indices = self.index.search(vectors.reshape(-1,23).astype('float32'), k) 
        return [self.labels[i] for i in indices[0]]

LSH_index = LSHIndex(data["vector"], data["attr"])
LSH_index.build()
# Here you spacify description from your choice
# Perfume_vector = will convert the attribute into veactor_based to find the similarities
perfume_vector, perfume_attr = data['vector'][list(data['attr']).index("mossy oakmoss woody phenolic earthy")], data['attr'][list(data['attr']).index("mossy oakmoss woody phenolic earthy")]
start = time.time()
simlar_perfume = '\n --'.join(LSH_index.query(perfume_vector))
# print(simlar_perfume ingredients)
simlar_perfume_v1 = LSH_index.query(perfume_vector)
for i in simlar_perfume_v1:
  print('Aroma_Chemical - '+str(df1[df1['Odor_Description']==str(i)]['Aroma_Chemical'].iloc[0]))
  print('Perfume Family - '+str(df1[df1['Odor_Description']==str(i)]['Family'].iloc[0]))
  print('Perfume Odor_Strength - '+str(df1[df1['Odor_Description']==str(i)]['Odor_Strength'].iloc[0]))
  print('Perfumary_Note - '+str(df1[df1['Odor_Description']==str(i)]['Perfumary_Note'].iloc[0]))
  print('************')
  # print(i)
end = time.time()
print('time taken '+ str(end - start))

"""# Search Algorithm (2) : Approximate Nearest Neighbor (vector encoding using trees)
#### There are some other libraries to do nearest neighbor search. Annoy is almost as fast as the fastest libraries, (see below), but there is actually another feature that really sets Annoy apart: it has the ability to use static files as indexes. In particular, this means you can share index across processes. Annoy also decouples creating indexes from loading them, so you can pass around indexes as files and map them into memory quickly. Another nice thing of Annoy is that it tries to minimize memory footprint so the indexes are quite small.
"""

# The idea of this code is to find the similarity of existing observations
# This is between a specific description of one data point in the database with other data points
import annoy

class AnnoyIndex():
    def __init__(self, vectors, labels):
        self.dimention = vectors.shape[1]
        self.vectors = vectors.astype('float32')
        self.labels = labels


    def build(self, number_of_trees=5):
        self.index = annoy.AnnoyIndex(self.dimention)
        for i, vec in enumerate(self.vectors):
            self.index.add_item(i, vec.tolist())
        self.index.build(number_of_trees)
        
    def query(self, vector, k=7):
        indices = self.index.get_nns_by_vector(vector.tolist(), k)
        return [self.labels[i] for i in indices]


ANN_index = AnnoyIndex(data["vector"], data["attr"])
ANN_index.build()

perfume_vector, perfume_attr = data['vector'][3], data['attr'][3] # Here you spicify one data point and find its similarity with others
start = time.time()
simlar_perfumes = '\n* '.join(ANN_index.query(perfume_vector))
# print(simlar_perfumes ingredients)
simlar_perfume_v1 = ANN_index.query(perfume_vector)
for i in simlar_perfume_v1:
  print('Aroma_Chemical - '+str(df1[df1['Odor_Description']==str(i)]['Aroma_Chemical'].iloc[0]))
  print('Perfume Family - '+str(df1[df1['Odor_Description']==str(i)]['Family'].iloc[0]))
  print('Perfume Odor_Strength - '+str(df1[df1['Odor_Description']==str(i)]['Odor_Strength'].iloc[0]))
  print('Perfumary_Note - '+str(df1[df1['Odor_Description']==str(i)]['Perfumary_Note'].iloc[0]))
  print('************')
end = time.time()
print('time taken '+ str(end - start))

perfume_vector

"""## Search Algorithm (3) : Okapi Best Match 25 (BM25)
#### BM25 improves upon TF*IDF. BM25 stands for “Best Match 25”. Released in 1994, it’s the 25th iteration of tweaking the relevance computation. BM25 has its roots in probabilistic information retrieval. Probabilistic information retrieval is a fascinating field unto itself. Basically, it casts relevance as a probability problem. A relevance score, according to probabilistic information retrieval, ought to reflect the probability a user will consider the result relevant. In this dataset we will use description based search with word embeddings.
"""

df2 = pd.read_excel('Essential_oils.xlsx')
df2.head()

text_list = df2.Odor_Description.str.lower().values
tok_text=[] # for our tokenised corpus
#Tokenising using SpaCy:
for doc in tqdm(nlp.pipe(text_list, disable=["tagger", "parser","ner"])):
    tok = [t.text for t in doc if t.is_alpha]
    tok_text.append(tok)

bm25 = BM25Okapi(tok_text)

def sim_search(query):
    tokenized_query = query.lower().split(" ")
    import time
    t0 = time.time()
    results = bm25.get_top_n(tokenized_query, df2.Odor_Description.values, n=7)
    t1 = time.time()
    for i in results:
      print('**********')
      print('Oil name - '+ str(df2[df2['Odor_Description']==i]['Ess_Oil_Name'].iloc[0]))
      print('Perfumary_Note - '+str(df2[df2['Odor_Description']==i]['Perfumary_Note'].iloc[0]))
      print('Perfume family - '+ str(df2[df2['Odor_Description']==i]['Family'].iloc[0]))
      print('Good for blend with - '+ str(df2[df2['Odor_Description']==i]['Blends_with'].iloc[0]))
      print('**********')

query = "fresh amber aldehydic moss citrus tuberose metallic waxy coumarinic"

sim_search(query)

# This is to be user interface for BM-25 application

search = input("Please enter the search string!!")
sim_search(search)

